# ğŸ§® MÃ©todos NumÃ©ricos en C++

Una colecciÃ³n completa de implementaciones de mÃ©todos numÃ©ricos fundamentales desarrollados en C++, diseÃ±ados para el aprendizaje y aplicaciÃ³n prÃ¡ctica en anÃ¡lisis numÃ©rico, cÃ¡lculo numÃ©rico y resoluciÃ³n de ecuaciones.

## ğŸ“š Tabla de Contenidos

- [ğŸš€ InstalaciÃ³n y CompilaciÃ³n](#-instalaciÃ³n-y-compilaciÃ³n)
- [ğŸ“ Estructura del Proyecto](#-estructura-del-proyecto)
- [ğŸ”¢ MÃ³dulos Disponibles](#-mÃ³dulos-disponibles)
  - [ğŸ¯ LocalizaciÃ³n de RaÃ­ces](#-localizaciÃ³n-de-raÃ­ces)
  - [ğŸ“ˆ InterpolaciÃ³n](#-interpolaciÃ³n)
  - [ğŸ§® IntegraciÃ³n NumÃ©rica](#-integraciÃ³n-numÃ©rica)
  - [ğŸ“Š DerivaciÃ³n NumÃ©rica](#-derivaciÃ³n-numÃ©rica)
  - [âš–ï¸ Sistemas de Ecuaciones Lineales](#ï¸-sistemas-de-ecuaciones-lineales)
  - [ğŸ“‰ RegresiÃ³n](#-regresiÃ³n)
  - [ğŸ”§ Ecuaciones Diferenciales](#-ecuaciones-diferenciales)
- [ğŸ’» GuÃ­a de Uso](#-guÃ­a-de-uso)
- [ğŸ“– Ejemplos PrÃ¡cticos](#-ejemplos-prÃ¡cticos)
- [ğŸ› ï¸ ContribuciÃ³n](#ï¸-contribuciÃ³n)

## ğŸš€ InstalaciÃ³n y CompilaciÃ³n

### Requisitos Previos
- Compilador C++ (g++, clang++, o equivalente)
- Sistema operativo: Linux, macOS, o Windows con MinGW

### CompilaciÃ³n RÃ¡pida
```bash
# Clonar el repositorio
git clone https://github.com/CEGB03/Metodos-Numericos-CPP.git
cd Metodos-Numericos-CPP

# Compilar cualquier mÃ³dulo
g++ -o programa "ruta/del/archivo.cpp"
./programa
```

## ğŸ“ Estructura del Proyecto

```
Metodos-Numericos-Cpp/
â”œâ”€â”€ ğŸ“ LocRaices/
â”‚   â”œâ”€â”€ ğŸ“ Abiertos/
â”‚   â”‚   â”œâ”€â”€ Newton-Raphson.cpp     # MÃ©todo de Newton-Raphson
â”‚   â”‚   â”œâ”€â”€ Punto-Fijo.cpp         # MÃ©todo de Punto Fijo
â”‚   â””â”€â”€ ğŸ“ Cerrados/
â”‚       â”œâ”€â”€ Biseccion.cpp          # MÃ©todo de BisecciÃ³n
â”‚       â””â”€â”€ RegulaFalsi.cpp        # MÃ©todo de Regula Falsi
â”œâ”€â”€ ğŸ“ Interpolacion/
â”‚   â”œâ”€â”€ interpolacion.cpp          # Lagrange y Vandermonde
â”‚   â”œâ”€â”€ Spline.cpp                # Splines de grado variable
â”‚   â”œâ”€â”€ data.txt                  # Datos de prueba
â”œâ”€â”€ ğŸ“ Integracion/
â”‚   â”œâ”€â”€ Integracion Newton Cotes.cpp  # Trapecio y Simpson
â”‚   â””â”€â”€ Gauss-Legendre.cpp        # Cuadratura Gauss-Legendre
â”œâ”€â”€ ğŸ“ Diferenciacion Numerica/
â”‚   â”œâ”€â”€ Derivadas.cpp             # Diferencias finitas
â”‚   â”œâ”€â”€ ğŸ“ Diferenciacion/
â”‚   â”‚   â””â”€â”€ Diferenciacion.cpp    # ImplementaciÃ³n alternativa
â”‚   â””â”€â”€ ğŸ“ Ecuaciones Diferenciales/
â”‚       â”œâ”€â”€ MetodoEuler.cpp       # MÃ©todo de Euler
â”‚       â”œâ”€â”€ MetodoHeun.cpp        # MÃ©todo de Heun
â”‚       â”œâ”€â”€ Runge-Kutta4.cpp      # Runge-Kutta 4to orden
â”‚       â”œâ”€â”€ MetodoPuntoMedio.cpp  # MÃ©todo del Punto Medio
â”‚       â””â”€â”€ EjemploEcsDifDeOrdenSuperior.cpp
â”œâ”€â”€ ğŸ“ Sistemas de Ecuaciones Lineales/
â”‚   â”œâ”€â”€ Eliminacion-Gaussiana.cpp  # EliminaciÃ³n Gaussiana
â”‚   â”œâ”€â”€ MÃ©todos Iterativos.cpp     # Jacobi, Gauss-Seidel, RelajaciÃ³n
â”‚   â”œâ”€â”€ data.txt                  # Datos de prueba
â”œâ”€â”€ ğŸ“ Regresion/
â”‚   â”œâ”€â”€ Regresion Lineal.cpp      # RegresiÃ³n lineal
â”‚   â”œâ”€â”€ polynomialRegression.cpp  # RegresiÃ³n polinÃ³mica
â”œâ”€â”€ .gitignore                    # Archivos ignorados
â””â”€â”€ README.md                     # Este archivo
```
      a# Ejecutable

## ğŸ”¢ MÃ³dulos Disponibles

### ğŸ¯ LocalizaciÃ³n de RaÃ­ces

#### ğŸ“„ `LocRaices/Abiertos/Newton-Raphson.cpp`
**MÃ©todo de Newton-Raphson para encontrar raÃ­ces con convergencia cuadrÃ¡tica**

**ğŸ¯ QuÃ© hace:**
- Localiza raÃ­ces de ecuaciones no lineales usando la fÃ³rmula: `xâ‚ = xâ‚€ - f(xâ‚€)/f'(xâ‚€)`
- Convergencia cuadrÃ¡tica (muy rÃ¡pida)
- Requiere la derivada de la funciÃ³n

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o newton LocRaices/Abiertos/Newton-Raphson.cpp

# Ejecutar
./newton
```

**ğŸ“ Modificar funciÃ³n:**
```cpp
// En el cÃ³digo fuente, cambiar estas dos funciones:
double f(double x) {
    return x * x - 4;  // Tu funciÃ³n f(x) aquÃ­
}

double fPrima(double x) {
    return 2 * x;      // Derivada f'(x) aquÃ­
}
```

**ğŸ“Š Entrada esperada:**
```
Tolerancia: 0.0001
Punto inicial: 1.5
```

**ğŸ“ˆ Salida tÃ­pica:**
```
=== MÃ‰TODO DE NEWTON-RAPHSON ===
FunciÃ³n: f(x) = xÂ² - 4
Derivada: f'(x) = 2x

IteraciÃ³n 1:
  f(xâ‚€) = -1.750000
  f'(xâ‚€) = 3.000000
  xâ‚ = 2.083333

âœ“ RaÃ­z encontrada: x = 2.000000
âœ“ Convergencia EXITOSA en 4 iteraciones
```

**âš¡ CaracterÃ­sticas:**
- âœ… Convergencia cuadrÃ¡tica sÃºper rÃ¡pida
- âœ… CÃ¡lculo de errores porcentuales y exactos
- âœ… Tabla detallada de iteraciones
- âœ… ValidaciÃ³n de derivada no nula
- âŒ Requiere derivada analÃ­tica
- âŒ Puede no converger si punto inicial es malo

#### ğŸ“„ `LocRaices/Abiertos/Punto-Fijo.cpp`
**TransformaciÃ³n f(x) = 0 â†’ x = g(x) para localizaciÃ³n iterativa**

**ğŸ¯ QuÃ© hace:**
- Transforma ecuaciÃ³n f(x) = 0 en punto fijo x = g(x)
- IteraciÃ³n: xâ‚ = g(xâ‚€), xâ‚‚ = g(xâ‚), ...
- VerificaciÃ³n automÃ¡tica de convergencia |g'(x)| < 1

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o punto-fijo LocRaices/Abiertos/Punto-Fijo.cpp

# Ejecutar
./punto-fijo
```

**ğŸ“ Estrategias para obtener g(x):**

| MÃ©todo | Ejemplo | g(x) resultante |
|--------|---------|-----------------|
| **Despeje directo** | f(x) = xÂ² - 4 = 0 | g(x) = 2 (raÃ­z positiva) |
| **FÃ³rmula general** | Cualquier f(x) | g(x) = x - Î»*f(x) con Î» = 0.1 |
| **TransformaciÃ³n** | f(x) = cos(x) - x | g(x) = cos(x) |

```cpp
// Modificar en el cÃ³digo fuente:
double g(double x) { 
    return 2;  // Para f(x) = xÂ² - 4, raÃ­z positiva
    // return cos(x);        // Para f(x) = cos(x) - x
    // return x - 0.1*f(x);  // FÃ³rmula general
}
```

**ğŸ“Š CaracterÃ­sticas:**
- âœ… No requiere derivada
- âœ… VerificaciÃ³n automÃ¡tica |g'(x)| < 1
- âœ… MÃºltiples estrategias de transformaciÃ³n
- âœ… LÃ­mite de seguridad de iteraciones
- âŒ Convergencia puede ser lenta
- âŒ Requiere anÃ¡lisis previo de g(x)

#### ğŸ“„ `LocRaices/Cerrados/Biseccion.cpp`
**MÃ©todo de BisecciÃ³n con convergencia garantizada**

**ğŸ¯ QuÃ© hace:**
- Localiza raÃ­ces en intervalo [a,b] donde f(a)Â·f(b) < 0
- Divide iterativamente el intervalo por la mitad
- Convergencia garantizada si hay cambio de signo

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o biseccion LocRaices/Cerrados/Biseccion.cpp

# Ejecutar
./biseccion
```

**ğŸ“ Modificar funciÃ³n:**
```cpp
double funcion(double x) {
    return log(x) + exp(sin(x)) - x;  // Tu funciÃ³n aquÃ­
}
```

**ğŸ“Š Entrada tÃ­pica:**
```
LÃ­mite inferior: 0.5
LÃ­mite superior: 1.0
Tolerancia: 0.0001
```

**âš¡ CaracterÃ­sticas:**
- âœ… Convergencia SIEMPRE garantizada
- âœ… Muy robusto y estable
- âœ… No requiere derivada
- âœ… Maneja funciones complicadas
- âŒ Convergencia lineal (lenta)
- âŒ Solo encuentra una raÃ­z por intervalo

#### ğŸ“„ `LocRaices/Cerrados/RegulaFalsi.cpp`
**MÃ©todo de Regula Falsi (Falsa PosiciÃ³n) - InterpolaciÃ³n lineal**

**ğŸ¯ QuÃ© hace:**
- Similar a bisecciÃ³n pero usa interpolaciÃ³n lineal
- FÃ³rmula: `c = (a*f(b) - b*f(a))/(f(b) - f(a))`
- MÃ¡s rÃ¡pido que bisecciÃ³n, mantiene convergencia garantizada

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o regula-falsi LocRaices/Cerrados/RegulaFalsi.cpp

# Ejecutar
./regula-falsi
```

**âš¡ CaracterÃ­sticas:**
- âœ… Convergencia garantizada como bisecciÃ³n
- âœ… MÃ¡s rÃ¡pido que bisecciÃ³n
- âœ… Interpola en lugar de dividir por la mitad
- âœ… Robusto para funciones continuas
- âŒ Puede ser lento en algunos casos especiales

### ğŸ“ˆ InterpolaciÃ³n

#### ğŸ“„ `Interpolacion/interpolacion.cpp`
**MÃ©todos de Lagrange y Vandermonde con visualizaciÃ³n completa**

**ğŸ¯ QuÃ© hace:**
- **Lagrange:** Construye polinomio usando bases de Lagrange Li(x)
- **Vandermonde:** Resuelve sistema matricial para coeficientes
- ExpansiÃ³n automÃ¡tica a forma polinÃ³mica estÃ¡ndar P(x) = aâ‚€ + aâ‚x + ...

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o interpolacion Interpolacion/interpolacion.cpp

# Ejecutar (lee datos desde data.txt)
./interpolacion
```

**ğŸ“„ Formato archivo `data.txt`:**
```
1.0    800.0
3.5    2310.0
5.0    3090.0
7.0    3940.0
13.0   4755.0
```

**ğŸ“Š Salidas del programa:**

1. **Forma de Lagrange:**
```
P(x) = 800 * [(x-3.5)/(1-3.5) * (x-5)/(1-5) * ...]
     + 2310 * [(x-1)/(3.5-1) * (x-5)/(3.5-5) * ...]
```

2. **Forma estÃ¡ndar expandida:**
```
P(x) = 2.1543*xÂ³ - 15.234*xÂ² + 45.678*x + 123.456
```

3. **Coeficientes individuales:**
```
aâ‚€ = 123.456  (tÃ©rmino independiente)
aâ‚ = 45.678   (coeficiente de x)
aâ‚‚ = -15.234  (coeficiente de xÂ²)
aâ‚ƒ = 2.1543   (coeficiente de xÂ³)
```

**âš¡ CaracterÃ­sticas:**
- âœ… Lagrange: VisualizaciÃ³n completa paso a paso
- âœ… Vandermonde: Matriz de coeficientes explÃ­cita
- âœ… ExpansiÃ³n automÃ¡tica a forma estÃ¡ndar
- âœ… Lectura desde archivo data.txt
- âœ… InterpolaciÃ³n de valores especÃ­ficos
- âŒ Inestable para muchos puntos (grado alto)

#### ğŸ“„ `Interpolacion/Spline.cpp`
**Splines de grado variable - COMPLETAMENTE ADAPTABLE**

**ğŸ¯ QuÃ© hace:**
- Crea splines de **cualquier grado** (1=lineal, 2=cuadrÃ¡tico, 3=cÃºbico, etc.)
- Garantiza continuidad hasta derivada (grado-1)
- Condiciones de frontera naturales automÃ¡ticas
- VisualizaciÃ³n detallada por tramos

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o spline Interpolacion/Spline.cpp

# Ejecutar
./spline
```

**ğŸ“ Configurar grado del spline:**
```cpp
// En main(), lÃ­nea ~50:
int grado = 3;  // â† CAMBIAR AQUÃ EL GRADO DESEADO
// grado = 1: Spline lineal (Câ° - solo continuo)
// grado = 2: Spline cuadrÃ¡tico (CÂ¹ - continuo y derivable)  
// grado = 3: Spline cÃºbico (CÂ² - continuo hasta 2da derivada)
// grado = 4: Spline cuÃ¡rtico (CÂ³)
// ...y asÃ­ sucesivamente
```

**ğŸ“Š Ejemplo salida Spline CÃºbico:**
```
=== SPLINE CÃšBICO EN FORMA DETALLADA ===
S(x) = { -0.123456*xÂ³ + 2.345678*xÂ² - 5.678901*x + 800.000000 }  si 1.000 â‰¤ x â‰¤ 3.500
       { 0.098765*xÂ³ - 1.234567*xÂ² + 4.567890*x + 1234.567890 }  si 3.500 â‰¤ x â‰¤ 5.000
       { -0.045678*xÂ³ + 0.987654*xÂ² - 2.345678*x + 2000.000000 }  si 5.000 â‰¤ x â‰¤ 7.000
       { 0.012345*xÂ³ - 0.543210*xÂ² + 1.234567*x + 1500.000000 }  si 7.000 â‰¤ x â‰¤ 13.000

=== VERIFICACIÃ“N DE CONTINUIDAD ===
En x = 3.500: S1(3.500) = 2310.000000, S2(3.500) = 2310.000000, |diferencia| = 1.23e-12
En x = 5.000: S2(5.000) = 3090.000000, S3(5.000) = 3090.000000, |diferencia| = 4.56e-13
```

**âš¡ CaracterÃ­sticas:**
- âœ… **ADAPTABLE A CUALQUIER GRADO** - Solo cambiar una variable
- âœ… MatemÃ¡ticamente correcto para todos los grados
- âœ… Continuidad automÃ¡tica hasta derivada (grado-1)
- âœ… VerificaciÃ³n numÃ©rica de continuidad
- âœ… MÃºltiples formas de visualizaciÃ³n
- âœ… InterpolaciÃ³n de valores especÃ­ficos
- âœ… Muy estable para muchos puntos

### ğŸ§® IntegraciÃ³n NumÃ©rica

#### ğŸ“„ `Integracion/Integracion Newton Cotes.cpp`
**MÃ©todos de Trapecio y Simpson con menÃº interactivo completo**

**ğŸ¯ QuÃ© hace:**
- **Trapecio:** Aproxima Ã¡rea con trapecios (precisiÃ³n O(hÂ²))
- **Simpson:** Usa parÃ¡bolas para mayor precisiÃ³n (O(hâ´))
- Maneja funciones conocidas y datos tabulados
- DocumentaciÃ³n integrada completa

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o integracion "Integracion/Integracion Newton Cotes.cpp"

# Ejecutar
./integracion
```

**ğŸ“Š MenÃº interactivo:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        INTEGRACIÃ“N NUMÃ‰RICA (NEWTON-COTES)       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
0. Ver documentaciÃ³n de mÃ©todos
1. Trapecio - FunciÃ³n conocida      [f(x) = xÂ² + 1]
2. Trapecio - Tabla de datos        [puntos discretos]
3. Simpson Compuesto - FunciÃ³n      [f(x) = xÂ² + 1] 
4. Simpson Compuesto - Tabla        [puntos discretos]
5. Salir
```

**ğŸ“ FunciÃ³n actual:** `f(x) = xÂ² + 1`
```cpp
// Para cambiar funciÃ³n, modificar:
double funcion(double x){
    return pow(x,2) + 1;  // Tu funciÃ³n aquÃ­
}
```

**ğŸ“Š Casos de uso y precisiÃ³n:**

| MÃ©todo | PrecisiÃ³n | CuÃ¡ndo usar | Restricciones |
|--------|-----------|-------------|---------------|
| **Trapecio FunciÃ³n** | O(hÂ²) | FunciÃ³n conocida, robustez | Ninguna especial |
| **Trapecio Tabla** | O(hÂ²) | Datos experimentales | MÃ­nimo 2 puntos |
| **Simpson FunciÃ³n** | O(hâ´) | FunciÃ³n conocida, precisiÃ³n | Intervalos PAR |
| **Simpson Tabla** | O(hâ´) | Datos experimentales precisos | Puntos equidistantes + intervalos PAR |

**ğŸ“‹ Ejemplo entrada Trapecio:**
```
LÃ­mite inferior (a): 0
LÃ­mite superior (b): 2  
NÃºmero de subintervalos (n): 4

Resultado: âˆ«[0,2] (xÂ²+1)dx â‰ˆ 4.6667
Valor exacto: 4.6667
Error absoluto: 8.33e-06
```

#### ğŸ“„ `Integracion/Gauss-Legendre.cpp`
**Cuadratura de Gauss-Legendre para alta precisiÃ³n**

**ğŸ¯ QuÃ© hace:**
- IntegraciÃ³n de alta precisiÃ³n con pocos puntos de evaluaciÃ³n
- Usa puntos y pesos pre-calculados Ã³ptimos
- Ã“rdenes disponibles: 2, 3, 4, 5, 6 puntos
- TransformaciÃ³n automÃ¡tica de intervalos

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o gauss-legendre Integracion/Gauss-Legendre.cpp

# Ejecutar
./gauss-legendre
```

**ğŸ“Š PrecisiÃ³n por orden:**

| Orden | Puntos | Exacto para polinomios hasta grado |
|-------|--------|-------------------------------------|
| 2 | 2 puntos | 3 |
| 3 | 3 puntos | 5 |
| 4 | 4 puntos | 7 |
| 5 | 5 puntos | 9 |
| 6 | 6 puntos | 11 |

### ğŸ“Š DerivaciÃ³n NumÃ©rica

#### ğŸ“„ `Diferenciacion Numerica/Derivadas.cpp`
**Diferencias finitas para cÃ¡lculo de derivadas**

**ğŸ¯ QuÃ© hace:**
- **Progresivas:** `f'(x) â‰ˆ [f(x+h) - f(x)]/h` - Para inicio de intervalo
- **Regresivas:** `f'(x) â‰ˆ [f(x) - f(x-h)]/h` - Para final de intervalo  
- **Centrales:** `f'(x) â‰ˆ [f(x+h) - f(x-h)]/(2h)` - Mejor precisiÃ³n O(hÂ²)
- **Segunda derivada:** `f''(x) â‰ˆ [f(x+h) - 2f(x) + f(x-h)]/hÂ²`

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o derivadas "Diferenciacion Numerica/Derivadas.cpp"

# Ejecutar
./derivadas
```

**ğŸ“Š Datos tabulados incluidos:**
```cpp
double a[FILAS][2] = {
    {0,    1},     {0.25, 1.384}, {0.5,  1.849}, {0.75, 2.417},
    {1,    3.118}, {1.25, 3.99},  {1.5,  5.082}, {1.75, 6.45}, 
    {2,    8.189}
};
```

**ğŸ“ˆ Salida tÃ­pica:**
```
Derivadas calculadas:
(0, 2.532)      â† Diferencias progresivas
(0.25, 1.856)   â† Diferencias centrales
(0.5, 2.272)    â† Diferencias centrales
...
(1.75, 6.956)   â† Diferencias centrales  
(2, 7.476)      â† Diferencias regresivas
```

**âš¡ ComparaciÃ³n de mÃ©todos:**

| MÃ©todo | PrecisiÃ³n | UbicaciÃ³n | FÃ³rmula |
|--------|-----------|-----------|---------|
| **Progresiva** | O(h) | Extremo izquierdo | [f(x+h) - f(x)]/h |
| **Regresiva** | O(h) | Extremo derecho | [f(x) - f(x-h)]/h |
| **Central** | **O(hÂ²)** | **Punto interior** | **[f(x+h) - f(x-h)]/(2h)** â† Mejor |

### âš–ï¸ Sistemas de Ecuaciones Lineales

#### ğŸ“„ `Sistemas de Ecuaciones Lineales/Eliminacion-Gaussiana.cpp`
**EliminaciÃ³n Gaussiana con pivoteo parcial**

**ğŸ¯ QuÃ© hace:**
- Resuelve sistemas Ax = b mediante eliminaciÃ³n gaussiana
- Pivoteo parcial automÃ¡tico para estabilidad numÃ©rica
- VerificaciÃ³n de matriz singular
- CÃ¡lculo del determinante

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o gauss "Sistemas de Ecuaciones Lineales/Eliminacion-Gaussiana.cpp"

# Ejecutar (lee desde data.txt)
./gauss
```

**ğŸ“„ Formato archivo `data.txt` (matriz aumentada):**
```
1  2  1  4  13
0  2  4  3  28  
4  2  2  1  20
-3 1  3  2  6
```
Representa el sistema:
```
xâ‚ + 2xâ‚‚ + xâ‚ƒ + 4xâ‚„ = 13
     2xâ‚‚ + 4xâ‚ƒ + 3xâ‚„ = 28
4xâ‚ + 2xâ‚‚ + 2xâ‚ƒ + xâ‚„ = 20
-3xâ‚ + xâ‚‚ + 3xâ‚ƒ + 2xâ‚„ = 6
```

**ğŸ“Š Salida tÃ­pica:**
```
La norma es: -156.000000

Conjunto solucion:
x1 = 1.000000
x2 = 2.000000  
x3 = 3.000000
x4 = 1.000000
```

**âš¡ CaracterÃ­sticas:**
- âœ… Pivoteo automÃ¡tico para evitar divisiones por cero
- âœ… DetecciÃ³n de sistemas singulares
- âœ… Lectura desde archivo flexible
- âœ… CÃ¡lculo de determinante como verificaciÃ³n

#### ğŸ“„ `Sistemas de Ecuaciones Lineales/MÃ©todos Iterativos.cpp`
**Jacobi, Gauss-Seidel y RelajaciÃ³n para sistemas grandes**

**ğŸ¯ QuÃ© hace:**
- **Jacobi:** IteraciÃ³n simultÃ¡nea con valores previos
- **Gauss-Seidel:** Usa valores actualizados inmediatamente  
- **RelajaciÃ³n:** Gauss-Seidel con factor de aceleraciÃ³n Ï‰

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar  
g++ -o iterativos "Sistemas de Ecuaciones Lineales/MÃ©todos Iterativos.cpp"

# Ejecutar (lee desde data.txt)
./iterativos
```

**ğŸ“Š MenÃº de selecciÃ³n:**
```
Seleccione:
1 --> Jacobi 
2 --> Gauss Seidel 
3 --> Gauss Seidel con RelajaciÃ³n
```

**ğŸ“ VerificaciÃ³n dominancia diagonal:**
El programa verifica automÃ¡ticamente si la matriz es diagonalmente dominante:
```cpp
|aii| > Î£|aij|  para todo iâ‰ j
```

**âš¡ ParÃ¡metros de relajaciÃ³n:**
- `Ï‰ = 1`: Gauss-Seidel normal
- `Ï‰ < 1`: Sub-relajaciÃ³n (mejora convergencia en casos difÃ­ciles)
- `Ï‰ > 1`: Sobre-relajaciÃ³n (acelera convergencia)

**ğŸ“Š ComparaciÃ³n mÃ©todos iterativos:**

| MÃ©todo | Velocidad | Memoria | Requisitos |
|--------|-----------|---------|------------|
| **Jacobi** | Media | MÃ¡s | Dominancia diagonal |
| **Gauss-Seidel** | **RÃ¡pida** | **Menos** | **Dominancia diagonal** |
| **RelajaciÃ³n** | **Variable** | Menos | Dominancia + parÃ¡metro Ï‰ |

### ğŸ“‰ RegresiÃ³n

#### ğŸ“„ `Regresion/Regresion Lineal.cpp`
**RegresiÃ³n lineal por mÃ­nimos cuadrados con anÃ¡lisis estadÃ­stico**

**ğŸ¯ QuÃ© hace:**
- Ajusta recta y = aâ‚€ + aâ‚x a datos experimentales
- Calcula coeficientes por mÃ­nimos cuadrados
- AnÃ¡lisis estadÃ­stico: RÂ², error estÃ¡ndar, correlaciÃ³n

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o regresion-lineal "Regresion/Regresion Lineal.cpp"

# Ejecutar
./regresion-lineal
```

**ğŸ“Š Datos de ejemplo incluidos:**
```cpp
double m[ROWS][2];
m[0][0] = -1; m[0][1] = 10;
m[1][0] = 0;  m[1][1] = 9;
m[2][0] = 1;  m[2][1] = 7;
m[3][0] = 2;  m[3][1] = 5;
// ... mÃ¡s puntos
```

**ğŸ“ˆ Salida tÃ­pica:**
```
Matriz del sistema:
    28.000000    14.000000    38.000000
    14.000000     8.000000    38.000000

Conjunto soluciÃ³n:
X0 = -1.607143  (pendiente aâ‚)
X1 = 9.107143   (intercepto aâ‚€)

EcuaciÃ³n de regresiÃ³n: y = 9.107143 - 1.607143*x

El error cuadrÃ¡tico medio es de: 0.534522
El coeficiente de correlaciÃ³n es: 0.982745
```

**ğŸ“Š MÃ©tricas calculadas:**
- **RÂ²**: Coeficiente de determinaciÃ³n (0-1, mÃ¡s cerca de 1 = mejor ajuste)
- **Error cuadrÃ¡tico medio**: DesviaciÃ³n promedio de los datos
- **Coeficiente de correlaciÃ³n**: Fuerza de relaciÃ³n lineal

#### ğŸ“„ `Regresion/polynomialRegression.cpp`
**RegresiÃ³n polinÃ³mica de grado variable con anÃ¡lisis completo**

**ğŸ¯ QuÃ© hace:**
- Ajusta polinomio P(x) = aâ‚€ + aâ‚x + aâ‚‚xÂ² + ... + aâ‚™xâ¿
- Grado configurable segÃºn datos disponibles
- AnÃ¡lisis estadÃ­stico detallado
- ValidaciÃ³n automÃ¡tica de viabilidad

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o regresion-poli Regresion/polynomialRegression.cpp

# Ejecutar
./regresion-poli
```

**ğŸ“Š Datos incluidos:**
```cpp
double nodes[6][2] = {
    {0.2, -0.94}, {0.6, -0.26}, {1.3, 2.35},
    {1.4, 2.94},  {1.8, 5.45},  {2.0, 7.20}
};
```

**ğŸ“ SelecciÃ³n de grado:**
```
----------------------------
Ingresar grado del polinomio: 
----------------------------
2    â† Usuario ingresa grado deseado
```

**ğŸ“ˆ Salida para polinomio grado 2:**
```
POLINOMIO
-2.34567 + 1.45678 X^1 + 0.987654 X^2

--------
DETALLES  
--------
Error/Residuo (suma de cuadrados): 0.123456
Error cuadrÃ¡tico medio: 0.161245  
DesviaciÃ³n estÃ¡ndar: 0.198765
Coeficiente de determinaciÃ³n: 0.987654
Coeficiente de correlaciÃ³n: 0.993827
```

**âš¡ ValidaciÃ³n automÃ¡tica:**
- Verifica que haya suficientes puntos para el grado solicitado
- Detecta sistemas singulares  
- Calcula todas las mÃ©tricas estadÃ­sticas relevantes

### ğŸ”§ Ecuaciones Diferenciales

#### ğŸ“„ `Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoEuler.cpp`
**MÃ©todo de Euler bÃ¡sico para EDO de primer orden**

**ğŸ¯ QuÃ© hace:**
- Resuelve EDO: `dy/dx = f(x,y)` con condiciÃ³n inicial `y(xâ‚€) = yâ‚€`
- MÃ©todo mÃ¡s simple: `yâ‚ = yâ‚€ + h*f(xâ‚€,yâ‚€)`
- PrecisiÃ³n O(h), fÃ¡cil de implementar

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o euler "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoEuler.cpp"

# Ejecutar
./euler
```

**ğŸ“ FunciÃ³n actual:** `f(x,y) = -2xy`
```cpp
// Para cambiar EDO, modificar:
double f(double x, double y){
    return (-2*x*y);  // Tu funciÃ³n f(x,y) aquÃ­
}
```

**ğŸ“Š Entrada tÃ­pica:**
```
Intervalo [a,b]
a: 0
b: 1
Cantidad de puntos: 10
Ingrese x0 e y0
x0: 0
y0: 1
```

**ğŸ“ˆ Salida paso a paso:**
```
X1 = 0.100000
Y1 = 1.000000
X2 = 0.200000  
Y2 = 0.980000
X3 = 0.300000
Y3 = 0.941200
...
```

#### ğŸ“„ `Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoHeun.cpp`
**MÃ©todo de Heun (Euler mejorado) - Predictor-Corrector**

**ğŸ¯ QuÃ© hace:**
- Esquema predictor-corrector para mayor precisiÃ³n
- **Predictor:** `y*â‚ = yâ‚€ + h*f(xâ‚€,yâ‚€)` (como Euler)
- **Corrector:** `yâ‚ = yâ‚€ + (h/2)[f(xâ‚€,yâ‚€) + f(xâ‚,y*â‚)]`
- PrecisiÃ³n O(hÂ²) - Mucho mejor que Euler

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar  
g++ -o heun "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoHeun.cpp"

# Ejecutar
./heun
```

**âš¡ CaracterÃ­sticas:**
- âœ… Mejor precisiÃ³n que Euler con poco esfuerzo extra
- âœ… Esquema auto-correctivo
- âœ… Buen balance precisiÃ³n/costo computacional

#### ğŸ“„ `Diferenciacion Numerica/Ecuaciones Diferenciales/Runge-Kutta4.cpp`
**Runge-Kutta 4to orden - El estÃ¡ndar de oro para EDO**

**ğŸ¯ QuÃ© hace:**
- MÃ©todo de 4to orden mÃ¡s utilizado en la prÃ¡ctica
- Calcula 4 coeficientes kâ‚, kâ‚‚, kâ‚ƒ, kâ‚„ por paso
- PrecisiÃ³n O(hâ´) - Excelente para la mayorÃ­a de problemas
- Muy estable y confiable

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o rk4 "Diferenciacion Numerica/Ecuaciones Diferenciales/Runge-Kutta4.cpp"

# Ejecutar
./rk4
```

**ğŸ“ FunciÃ³n actual:** `f(x,y) = xâˆšy`
```cpp
double f(double x, double y){
    return x*sqrt(y);  // Tu EDO aquÃ­: dy/dx = xâˆšy
}
```

**ğŸ”¬ Algoritmo interno:**
```
kâ‚ = f(xáµ¢, yáµ¢)
kâ‚‚ = f(xáµ¢ + h/2, yáµ¢ + kâ‚h/2)  
kâ‚ƒ = f(xáµ¢ + h/2, yáµ¢ + kâ‚‚h/2)
kâ‚„ = f(xáµ¢ + h, yáµ¢ + kâ‚ƒh)
yáµ¢â‚Šâ‚ = yáµ¢ + (h/6)(kâ‚ + 2kâ‚‚ + 2kâ‚ƒ + kâ‚„)
```

#### ğŸ“„ `Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoPuntoMedio.cpp`
**MÃ©todo del Punto Medio con evaluaciÃ³n central**

**ğŸ¯ QuÃ© hace:**
- EvalÃºa la derivada en el punto medio del intervalo
- `yâ‚ = yâ‚€ + h*f(xâ‚€ + h/2, yâ‚€ + (h/2)*f(xâ‚€,yâ‚€))`
- PrecisiÃ³n O(hÂ²) con un enfoque diferente

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o punto-medio "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoPuntoMedio.cpp"

# Ejecutar  
./punto-medio
```

#### ğŸ“„ `Diferenciacion Numerica/Ecuaciones Diferenciales/EjemploEcsDifDeOrdenSuperior.cpp`
**Sistemas de EDO usando Runge-Kutta - Orden superior reducido a primer orden**

**ğŸ¯ QuÃ© hace:**
- Resuelve EDO de orden superior convirtiÃ©ndolas en sistemas
- Ejemplo: `y'' + y = 4cos(x)` â†’ Sistema: `yâ‚' = yâ‚‚, yâ‚‚' = -yâ‚ + 4cos(x)`
- Aplica RK4 simultÃ¡neamente a ambas ecuaciones

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o edo-superior "Diferenciacion Numerica/Ecuaciones Diferenciales/EjemploEcsDifDeOrdenSuperior.cpp"

# Ejecutar
./edo-superior
```

**ğŸ“Š Sistema actual:**
```cpp
double f1(double y2){
    return y2;  // yâ‚' = yâ‚‚
}
double f2(double x, double y1){  
    return -y1 + 4*cos(x);  // yâ‚‚' = -yâ‚ + 4cos(x)
}
```

**ğŸ“ˆ Condiciones iniciales:** `y(0) = 0, y'(0) = 0`

## ğŸ’» GuÃ­a de Uso

### CompilaciÃ³n de MÃ³dulos EspecÃ­ficos

```bash
# LocalizaciÃ³n de RaÃ­ces
g++ -o newton LocRaices/Abiertos/Newton-Raphson.cpp
g++ -o punto-fijo LocRaices/Abiertos/Punto-Fijo.cpp
g++ -o biseccion LocRaices/Cerrados/Biseccion.cpp
g++ -o regula-falsi LocRaices/Cerrados/RegulaFalsi.cpp

# InterpolaciÃ³n
g++ -o interpolacion Interpolacion/interpolacion.cpp
g++ -o spline Interpolacion/Spline.cpp

# IntegraciÃ³n
g++ -o integracion "Integracion/Integracion Newton Cotes.cpp"
g++ -o gauss-legendre Integracion/Gauss-Legendre.cpp

# Derivadas y EDO
g++ -o derivadas "Diferenciacion Numerica/Derivadas.cpp"
g++ -o euler "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoEuler.cpp"
g++ -o heun "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoHeun.cpp"
g++ -o rk4 "Diferenciacion Numerica/Ecuaciones Diferenciales/Runge-Kutta4.cpp"
g++ -o punto-medio "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoPuntoMedio.cpp"
g++ -o edo-superior "Diferenciacion Numerica/Ecuaciones Diferenciales/EjemploEcsDifDeOrdenSuperior.cpp"

# Sistemas de Ecuaciones
g++ -o gauss "Sistemas de Ecuaciones Lineales/Eliminacion-Gaussiana.cpp"
g++ -o iterativos "Sistemas de Ecuaciones Lineales/MÃ©todos Iterativos.cpp"

# RegresiÃ³n
g++ -o regresion-lineal "Regresion/Regresion Lineal.cpp"
g++ -o regresion-poli Regresion/polynomialRegression.cpp
```

### Archivos de Datos

Algunos programas requieren archivos de entrada especÃ­ficos:

#### **ğŸ“„ `Interpolacion/data.txt`** (para interpolaciÃ³n):
```
1.0    800.0
3.5    2310.0
5.0    3090.0
7.0    3940.0
13.0   4755.0
```

#### **ğŸ“„ `Sistemas de Ecuaciones Lineales/data.txt`** (matriz aumentada):
```
1  2  1  4  13
0  2  4  3  28
4  2  2  1  20
-3 1  3  2  6
```

### PersonalizaciÃ³n de Funciones

#### **Para mÃ©todos de raÃ­ces:**
```cpp
// Newton-Raphson.cpp
double f(double x) {
    return x*x*x - 2*x + 1;  // f(x) = xÂ³ - 2x + 1
}
double fPrima(double x) {
    return 3*x*x - 2;        // f'(x) = 3xÂ² - 2
}

// Punto-Fijo.cpp  
double g(double x) {
    return sqrt(2*x - 1);    // Para f(x) = xÂ² - 2x + 1
}
```

#### **Para integraciÃ³n:**
```cpp
// Integracion Newton Cotes.cpp
double funcion(double x){
    return sin(x) * exp(-x);  // Tu funciÃ³n a integrar
}
```

#### **Para EDO:**
```cpp
// Cualquier mÃ©todo de EDO
double f(double x, double y) {
    return x + y;            // Tu EDO: y' = x + y
}
```

#### **Para splines - Cambiar grado:**
```cpp
// Spline.cpp, en main():
int grado = 2;  // â† Cambiar: 1=lineal, 2=cuadrÃ¡tico, 3=cÃºbico, etc.
```

## ğŸ“– Ejemplos PrÃ¡cticos Completos

### Ejemplo 1: Encontrar âˆš2 usando diferentes mÃ©todos

#### **Newton-Raphson:**
```cpp
// f(x) = xÂ² - 2, f'(x) = 2x
double f(double x) { return x*x - 2; }
double fPrima(double x) { return 2*x; }
// Punto inicial: 1.5 â†’ Converge a 1.414213...
```

#### **Punto Fijo:**
```cpp
// g(x) = 2/x (converge a Â±âˆš2 segÃºn punto inicial)
double g(double x) { return 2.0/x; }
// Punto inicial: 1.0 â†’ Converge a 1.414213...
```

#### **BisecciÃ³n:**
```cpp
double funcion(double x) { return x*x - 2; }
// Intervalo [1, 2] â†’ Converge a 1.414213...
```

### Ejemplo 2: InterpolaciÃ³n de datos de temperatura

**Datos experimentales:**
```cpp
// data.txt
0.0    20.0    // t=0min,  T=20Â°C
10.0   35.2    // t=10min, T=35.2Â°C  
20.0   48.7    // t=20min, T=48.7Â°C
30.0   60.1    // t=30min, T=60.1Â°C
```

**Usar Lagrange para T(15min):**
```bash
./interpolacion
# Seleccionar mÃ©todo 1 (Lagrange)
# Interpolar valor: 15
# Resultado: T(15min) â‰ˆ 41.95Â°C
```

### Ejemplo 3: Integrar Ã¡rea bajo curva

**Calcular âˆ«â‚€Â² (xÂ²+1) dx:**
```bash
./integracion
# OpciÃ³n 3: Simpson Compuesto - FunciÃ³n
# a: 0, b: 2, intervalos: 4
# Resultado: 4.666667 (exacto para este polinomio)
```

### Ejemplo 4: Resolver EDO poblacional

**EDO:** `dy/dt = ky` (crecimiento exponencial)
```cpp
// En MetodoEuler.cpp o Runge-Kutta4.cpp:
double f(double t, double y) {
    return 0.1 * y;  // k = 0.1 (tasa crecimiento 10%)
}
// CondiciÃ³n inicial: y(0) = 100 (poblaciÃ³n inicial)
// SoluciÃ³n exacta: y(t) = 100*e^(0.1*t)
```

### Ejemplo 5: Sistema de ecuaciones 3x3

**Sistema:**
```
2x + y + z = 8
x + 3y + z = 10  
x + y + 4z = 12
```

**Archivo data.txt:**
```
2  1  1  8
1  3  1  10
1  1  4  12
```

**MÃ©todos disponibles:**
- **EliminaciÃ³n Gaussiana:** SoluciÃ³n directa
- **Jacobi/Gauss-Seidel:** Para sistemas grandes
- **Resultado esperado:** x=1, y=2, z=3

## ğŸ“Š GuÃ­a de SelecciÃ³n de MÃ©todos

### Para LocalizaciÃ³n de RaÃ­ces:

| SituaciÃ³n | MÃ©todo Recomendado | Velocidad | Robustez |
|-----------|-------------------|-----------|----------|
| Conoces f'(x) y buen punto inicial | **Newton-Raphson** | â­â­â­â­â­ | â­â­ |
| Puedes obtener g(x) fÃ¡cilmente | **Punto Fijo** | â­â­â­ | â­â­â­ |
| Tienes intervalo con cambio de signo | **BisecciÃ³n** | â­â­ | â­â­â­â­â­ |
| Quieres balance velocidad/robustez | **Regula Falsi** | â­â­â­ | â­â­â­â­ |

### Para InterpolaciÃ³n:

| SituaciÃ³n | MÃ©todo | Estabilidad | Suavidad |
|-----------|--------|-------------|----------|
| â‰¤ 8 puntos | **Lagrange** | â­â­â­ | â­â­â­ |
| > 8 puntos | **Spline cÃºbico** | â­â­â­â­â­ | â­â­â­â­â­ |
| Datos experimentales con ruido | **Spline lineal** | â­â­â­â­ | â­â­ |
| Necesitas funciÃ³n analÃ­tica | **Lagrange** | â­â­â­ | â­â­â­ |

### Para IntegraciÃ³n:

| Prioridad | MÃ©todo | PrecisiÃ³n | Esfuerzo |
|-----------|--------|-----------|----------|
| **MÃ¡xima precisiÃ³n** | **Gauss-Legendre** | â­â­â­â­â­ | â­â­â­ |
| **Balance** | **Simpson** | â­â­â­â­ | â­â­ |
| **Robustez** | **Trapecio** | â­â­â­ | â­ |
| **Datos irregulares** | **Trapecio tabla** | â­â­â­ | â­ |

### Para EDO:

| SituaciÃ³n | MÃ©todo | PrecisiÃ³n | Costo |
|-----------|--------|-----------|-------|
| **Aprendizaje/comprensiÃ³n** | **Euler** | â­â­ | â­ |
| **Balance precio/calidad** | **Heun** | â­â­â­ | â­â­ |
| **Aplicaciones reales** | **Runge-Kutta 4** | â­â­â­â­â­ | â­â­â­ |
| **Casos especÃ­ficos** | **Punto Medio** | â­â­â­ | â­â­ |

### Para Sistemas Lineales:

| TamaÃ±o del Sistema | MÃ©todo Recomendado | Memoria | PrecisiÃ³n |
|-------------------|-------------------|---------|-----------|
| **PequeÃ±o (< 100)** | **EliminaciÃ³n Gaussiana** | â­â­â­ | â­â­â­â­â­ |
| **Mediano (100-1000)** | **Gauss-Seidel** | â­â­â­â­ | â­â­â­â­ |
| **Grande (> 1000)** | **MÃ©todos Iterativos** | â­â­â­â­â­ | â­â­â­ |
| **Mal condicionado** | **Gaussiana + Pivoteo** | â­â­â­ | â­â­â­â­â­ |

## ğŸ› ï¸ SoluciÃ³n de Problemas Comunes

### âŒ **Error: "Matriz singular"**
**Problema:** Sistema sin soluciÃ³n Ãºnica
**SoluciÃ³n:**
- Verificar datos de entrada
- Comprobar dependencias lineales
- Usar pivoteo si disponible

### âŒ **Error: "No converge" en mÃ©todos iterativos**
**Problema:** Criterios de convergencia no cumplidos
**SoluciÃ³n:**
```cpp
// Para Newton-Raphson: f'(x) â‰  0
// Para Punto Fijo: |g'(x)| < 1
// Para sistemas: matriz diagonalmente dominante
```

### âŒ **Error: "NÃºmero PAR de intervalos" en Simpson**
**Problema:** Simpson requiere n par
**SoluciÃ³n:**
- Usar n = 2, 4, 6, 8...
- O cambiar a mÃ©todo del trapecio

### âŒ **PrecisiÃ³n baja en derivadas numÃ©ricas**
**Problema:** Valor de h inadecuado
**SoluciÃ³n:**
```cpp
// h muy grande â†’ Error de truncamiento
// h muy pequeÃ±o â†’ Errores de redondeo
// Valor Ã³ptimo: h âˆˆ [10â»â¶, 10â»Â³]
```

### âŒ **Spline no encuentra soluciÃ³n**
**Problema:** Grado demasiado alto para pocos puntos
**SoluciÃ³n:**
```cpp
// Regla: grado â‰¤ (nÃºmero_puntos - 1)
// Para 5 puntos: grado â‰¤ 4
if (grado > filas - 1) {
    cout << "Reducir grado a " << (filas-1) << endl;
}
```

## ğŸ› ï¸ ContribuciÃ³n

### CÃ³mo contribuir
1. **Fork** el repositorio
2. **Crear** rama: `git checkout -b feature/nueva-funcionalidad`
3. **Desarrollar** siguiendo las convenciones del proyecto
4. **Commit**: `git commit -m 'Add: nueva funcionalidad'`
5. **Push**: `git push origin feature/nueva-funcionalidad`
6. **Pull Request** con descripciÃ³n detallada

### Estilo de cÃ³digo
```cpp
// âœ… Nombres descriptivos en espaÃ±ol
void eliminacionGaussiana();
void interpolacionLagrange();

// âœ… Comentarios explicativos
// Aplica pivoteo parcial para evitar divisiÃ³n por cero

// âœ… Constantes definidas
#define FILAS 20
#define TOLERANCIA 1e-6

// âœ… ValidaciÃ³n de entrada
if (grado < 1 || grado > filas-1) {
    cout << "Error: grado invÃ¡lido" << endl;
    return;
}
```

### Ãreas de mejora sugeridas
- [ ] **Interfaz grÃ¡fica** con bibliotecas como FLTK o Qt
- [ ] **ParalelizaciÃ³n** con OpenMP para sistemas grandes
- [ ] **PrecisiÃ³n extendida** con bibliotecas como Boost.Multiprecision
- [ ] **Tests automatizados** con Google Test
- [ ] **DocumentaciÃ³n LaTeX** para formulas matemÃ¡ticas
- [ ] **Benchmarking** comparativo entre mÃ©todos

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la **Licencia MIT**. Puedes usar, modificar y distribuir libremente.

```
MIT License - Copyright (c) 2025 CEGB03

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

## ğŸ‘¨â€ğŸ’» Autor

**CEGB03** - [GitHub](https://github.com/CEGB03)

---

## ğŸš€ Roadmap Futuro

### PrÃ³ximas funcionalidades v2.0
- [ ] **MÃ©todos de elementos finitos** bÃ¡sicos
- [ ] **AnÃ¡lisis de Fourier** (FFT, DFT)
- [ ] **OptimizaciÃ³n numÃ©rica** (gradiente descendente, simplex)
- [ ] **AnÃ¡lisis de estabilidad** para mÃ©todos de EDO
- [ ] **IntegraciÃ³n adaptativa** (Romberg, Gauss-Kronrod)
- [ ] **Splines de tensiÃ³n** y B-splines
- [ ] **MÃ©todos de Monte Carlo** para integraciÃ³n
- [ ] **Solver para EDP** (diferencias finitas)

### Mejoras tÃ©cnicas v1.5
- [ ] **CMake build system** multiplataforma
- [ ] **Manejo de excepciones** robusto
- [ ] **Logging system** para debugging
- [ ] **ConfiguraciÃ³n JSON** para parÃ¡metros
- [ ] **API unificada** entre mÃ³dulos
- [ ] **DocumentaciÃ³n Doxygen** automÃ¡tica

---

## ğŸ“Š EstadÃ­sticas del Proyecto

| MÃ©trica | Valor |
|---------|-------|
| **LÃ­neas de cÃ³digo** | ~3,500+ |
| **Archivos fuente** | 15+ |
| **MÃ©todos implementados** | 25+ |
| **Ãreas cubiertas** | 7 |
| **Complejidad** | Intermedia-Avanzada |
| **Compatibilidad** | C++11+ |

---

**ğŸ“§ Â¿Preguntas, sugerencias o encontraste un bug?** 
Abre un [Issue](https://github.com/CEGB03/Metodos-Numericos-CPP/issues) o contribuye al proyecto.

**â­ Si este proyecto te ayudÃ³ en tus estudios o trabajo, Â¡dale una estrella!**

**ğŸ”— Comparte** este repositorio con compaÃ±eros de ingenierÃ­a, matemÃ¡ticas o ciencias de la computaciÃ³n.

---

*Desarrollado con ğŸ’» y â˜• para la comunidad de mÃ©todos numÃ©ricos*