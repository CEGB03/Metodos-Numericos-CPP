# ğŸ§® MÃ©todos NumÃ©ricos en C++

Una colecciÃ³n completa de implementaciones de mÃ©todos numÃ©ricos fundamentales desarrollados en C++, diseÃ±ados para el aprendizaje y aplicaciÃ³n prÃ¡ctica en anÃ¡lisis numÃ©rico, cÃ¡lculo numÃ©rico y resoluciÃ³n de ecuaciones.

## ğŸ“š Tabla de Contenidos

- [ğŸš€ InstalaciÃ³n y CompilaciÃ³n](#-instalaciÃ³n-y-compilaciÃ³n)
- [ğŸ“ Estructura del Proyecto](#-estructura-del-proyecto)
- [ğŸ“– OrganizaciÃ³n por Parciales](#-organizaciÃ³n-por-parciales)
- [ğŸ”¢ MÃ³dulos Disponibles](#-mÃ³dulos-disponibles)
  - [ğŸ“‹ PRIMER PARCIAL](#-primer-parcial)
    - [ğŸ¯ LocalizaciÃ³n de RaÃ­ces](#-localizaciÃ³n-de-raÃ­ces)
    - [âš–ï¸ Sistemas de Ecuaciones Lineales](#ï¸-sistemas-de-ecuaciones-lineales)
    - [ğŸ“‰ RegresiÃ³n](#-regresiÃ³n)
    - [ğŸ“ˆ InterpolaciÃ³n](#-interpolaciÃ³n)
  - [ğŸ“‹ SEGUNDO PARCIAL](#-segundo-parcial)
    - [ğŸ§® IntegraciÃ³n NumÃ©rica](#-integraciÃ³n-numÃ©rica)
    - [ğŸ“Š DerivaciÃ³n NumÃ©rica](#-derivaciÃ³n-numÃ©rica)
    - [ğŸ”§ Ecuaciones Diferenciales](#-ecuaciones-diferenciales)
- [ğŸ’» GuÃ­a de Uso](#-guÃ­a-de-uso)
- [ğŸ“– Ejemplos PrÃ¡cticos](#-ejemplos-prÃ¡cticos)
- [ğŸ› ï¸ ContribuciÃ³n](#ï¸-contribuciÃ³n)

## ğŸš€ InstalaciÃ³n y CompilaciÃ³n

### Requisitos Previos
- Compilador C++ (g++, clang++, o equivalente)
- Sistema operativo: Linux, macOS, o Windows con MinGW

### CompilaciÃ³n RÃ¡pida
```bash
# Clonar el repositorio
git clone https://github.com/CEGB03/Metodos-Numericos-CPP.git
cd Metodos-Numericos-CPP

# Compilar cualquier mÃ³dulo
g++ -o programa "ruta/del/archivo.cpp"
./programa
```

## ğŸ“ Estructura del Proyecto

```
Metodos-Numericos-Cpp/
â”œâ”€â”€ ğŸ“ LocRaices/                    [PRIMER PARCIAL]
â”‚   â”œâ”€â”€ ğŸ“ Abiertos/
â”‚   â”‚   â”œâ”€â”€ Newton-Raphson.cpp
â”‚   â”‚   â””â”€â”€ Punto-Fijo.cpp
â”‚   â””â”€â”€ ğŸ“ Cerrados/
â”‚       â”œâ”€â”€ Biseccion.cpp
â”‚       â””â”€â”€ RegulaFalsi.cpp
â”œâ”€â”€ ğŸ“ Sistemas de Ecuaciones Lineales/  [PRIMER PARCIAL]
â”‚   â”œâ”€â”€ Eliminacion-Gaussiana.cpp
â”‚   â””â”€â”€ MÃ©todos Iterativos.cpp
â”œâ”€â”€ ğŸ“ Regresion/                    [PRIMER PARCIAL]
â”‚   â”œâ”€â”€ Regresion Lineal.cpp
â”‚   â””â”€â”€ polynomialRegression.cpp
â”œâ”€â”€ ğŸ“ Interpolacion/                [PRIMER PARCIAL]
â”‚   â”œâ”€â”€ interpolacion.cpp
â”‚   â””â”€â”€ Spline.cpp
â”œâ”€â”€ ğŸ“ Integracion/                  [SEGUNDO PARCIAL]
â”‚   â”œâ”€â”€ Integracion Newton Cotes.cpp
â”‚   â””â”€â”€ Gauss-Legendre.cpp
â”œâ”€â”€ ğŸ“ Diferenciacion Numerica/      [SEGUNDO PARCIAL]
â”‚   â”œâ”€â”€ Derivadas.cpp
â”‚   â”œâ”€â”€ ğŸ“ Diferenciacion/
â”‚   â”‚   â””â”€â”€ Diferenciacion.cpp
â”‚   â””â”€â”€ ğŸ“ Ecuaciones Diferenciales/
â”‚       â”œâ”€â”€ MetodoEuler.cpp
â”‚       â”œâ”€â”€ MetodoHeun.cpp
â”‚       â”œâ”€â”€ Runge-Kutta4.cpp
â”‚       â”œâ”€â”€ MetodoPuntoMedio.cpp
â”‚       â””â”€â”€ EjemploEcsDifDeOrdenSuperior.cpp
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ“– OrganizaciÃ³n por Parciales

### ğŸ“‹ **PRIMER PARCIAL - MÃ©todos Fundamentales**
**Contenido:** LocalizaciÃ³n de raÃ­ces, sistemas lineales, regresiÃ³n e interpolaciÃ³n
- âœ… 4 mÃ©todos de localizaciÃ³n de raÃ­ces
- âœ… 2 mÃ©todos para sistemas lineales  
- âœ… 2 tipos de regresiÃ³n
- âœ… 2 mÃ©todos de interpolaciÃ³n

### ğŸ“‹ **SEGUNDO PARCIAL - AnÃ¡lisis Avanzado**  
**Contenido:** IntegraciÃ³n, derivaciÃ³n y ecuaciones diferenciales
- âœ… MÃ©todos de integraciÃ³n numÃ©rica
- âœ… DiferenciaciÃ³n numÃ©rica
- âœ… 5 mÃ©todos para ecuaciones diferenciales

---

# ğŸ”¢ MÃ³dulos Disponibles

# ğŸ“‹ PRIMER PARCIAL

## ğŸ¯ LocalizaciÃ³n de RaÃ­ces

### ğŸ“„ `LocRaices/Cerrados/Biseccion.cpp`
**MÃ©todo de BisecciÃ³n con convergencia garantizada**

**ğŸ¯ QuÃ© hace:**
- Localiza raÃ­ces en intervalo [a,b] donde f(a)Â·f(b) < 0
- Divide iterativamente el intervalo por la mitad
- Convergencia garantizada si hay cambio de signo

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o biseccion LocRaices/Cerrados/Biseccion.cpp

# Ejecutar
./biseccion
```

**ğŸ“ Modificar funciÃ³n:**
```cpp
double funcion(double x) {
    return log(x) + exp(sin(x)) - x;  // Tu funciÃ³n aquÃ­
}
```

**ğŸ“Š Entrada tÃ­pica:**
```
LÃ­mite inferior: 0.5
LÃ­mite superior: 1.0
Tolerancia: 0.0001
```

**âš¡ CaracterÃ­sticas:**
- âœ… Convergencia SIEMPRE garantizada
- âœ… Muy robusto y estable
- âœ… No requiere derivada
- âœ… Maneja funciones complicadas
- âŒ Convergencia lineal (lenta)
- âŒ Solo encuentra una raÃ­z por intervalo

### ğŸ“„ `LocRaices/Cerrados/RegulaFalsi.cpp`
**MÃ©todo de Regula Falsi (Falsa PosiciÃ³n) - InterpolaciÃ³n lineal**

**ğŸ¯ QuÃ© hace:**
- Similar a bisecciÃ³n pero usa interpolaciÃ³n lineal
- FÃ³rmula: `c = (a*f(b) - b*f(a))/(f(b) - f(a))`
- MÃ¡s rÃ¡pido que bisecciÃ³n, mantiene convergencia garantizada

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o regula-falsi LocRaices/Cerrados/RegulaFalsi.cpp

# Ejecutar
./regula-falsi
```

**âš¡ CaracterÃ­sticas:**
- âœ… Convergencia garantizada como bisecciÃ³n
- âœ… MÃ¡s rÃ¡pido que bisecciÃ³n
- âœ… Interpola en lugar de dividir por la mitad
- âœ… Robusto para funciones continuas
- âŒ Puede ser lento en algunos casos especiales

### ğŸ“„ `LocRaices/Abiertos/Punto-Fijo.cpp`
**TransformaciÃ³n f(x) = 0 â†’ x = g(x) para localizaciÃ³n iterativa**

**ğŸ¯ QuÃ© hace:**
- Transforma ecuaciÃ³n f(x) = 0 en punto fijo x = g(x)
- IteraciÃ³n: xâ‚ = g(xâ‚€), xâ‚‚ = g(xâ‚), ...
- VerificaciÃ³n automÃ¡tica de convergencia |g'(x)| < 1

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o punto-fijo LocRaices/Abiertos/Punto-Fijo.cpp

# Ejecutar
./punto-fijo
```

**ğŸ“ Estrategias para obtener g(x):**

| MÃ©todo | Ejemplo | g(x) resultante |
|--------|---------|-----------------|
| **Despeje directo** | f(x) = xÂ² - 4 = 0 | g(x) = 2 (raÃ­z positiva) |
| **FÃ³rmula general** | Cualquier f(x) | g(x) = x - Î»*f(x) con Î» = 0.1 |
| **TransformaciÃ³n** | f(x) = cos(x) - x | g(x) = cos(x) |

```cpp
// Modificar en el cÃ³digo fuente:
double g(double x) { 
    return 2;  // Para f(x) = xÂ² - 4, raÃ­z positiva
    // return cos(x);        // Para f(x) = cos(x) - x
    // return x - 0.1*f(x);  // FÃ³rmula general
}
```

### ğŸ“„ `LocRaices/Abiertos/Newton-Raphson.cpp`
**MÃ©todo de Newton-Raphson para encontrar raÃ­ces con convergencia cuadrÃ¡tica**

**ğŸ¯ QuÃ© hace:**
- Localiza raÃ­ces de ecuaciones no lineales usando la fÃ³rmula: `xâ‚ = xâ‚€ - f(xâ‚€)/f'(xâ‚€)`
- Convergencia cuadrÃ¡tica (muy rÃ¡pida)
- Requiere la derivada de la funciÃ³n

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o newton LocRaices/Abiertos/Newton-Raphson.cpp

# Ejecutar
./newton
```

**ğŸ“ Modificar funciÃ³n:**
```cpp
// En el cÃ³digo fuente, cambiar estas dos funciones:
double f(double x) {
    return x * x - 4;  // Tu funciÃ³n f(x) aquÃ­
}

double fPrima(double x) {
    return 2 * x;      // Derivada f'(x) aquÃ­
}
```

**ğŸ“Š Entrada esperada:**
```
Tolerancia: 0.0001
Punto inicial: 1.5
```

**ğŸ“ˆ Salida tÃ­pica:**
```
=== MÃ‰TODO DE NEWTON-RAPHSON ===
FunciÃ³n: f(x) = xÂ² - 4
Derivada: f'(x) = 2x

IteraciÃ³n 1:
  f(xâ‚€) = -1.750000
  f'(xâ‚€) = 3.000000
  xâ‚ = 2.083333

âœ“ RaÃ­z encontrada: x = 2.000000
âœ“ Convergencia EXITOSA en 4 iteraciones
```

## âš–ï¸ Sistemas de Ecuaciones Lineales

### ğŸ“„ `Sistemas de Ecuaciones Lineales/Eliminacion-Gaussiana.cpp`
**EliminaciÃ³n Gaussiana con pivoteo parcial**

**ğŸ¯ QuÃ© hace:**
- Resuelve sistemas Ax = b mediante eliminaciÃ³n gaussiana
- Pivoteo parcial automÃ¡tico para estabilidad numÃ©rica
- VerificaciÃ³n de matriz singular
- CÃ¡lculo del determinante

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o gauss "Sistemas de Ecuaciones Lineales/Eliminacion-Gaussiana.cpp"

# Ejecutar (lee desde data.txt)
./gauss
```

**ğŸ“„ Formato archivo `data.txt` (matriz aumentada):**
```
1  2  1  4  13
0  2  4  3  28  
4  2  2  1  20
-3 1  3  2  6
```
Representa el sistema:
```
xâ‚ + 2xâ‚‚ + xâ‚ƒ + 4xâ‚„ = 13
     2xâ‚‚ + 4xâ‚ƒ + 3xâ‚„ = 28
4xâ‚ + 2xâ‚‚ + 2xâ‚ƒ + xâ‚„ = 20
-3xâ‚ + xâ‚‚ + 3xâ‚ƒ + 2xâ‚„ = 6
```

**ğŸ“Š Salida tÃ­pica:**
```
La norma es: -156.000000

Conjunto solucion:
x1 = 1.000000
x2 = 2.000000  
x3 = 3.000000
x4 = 1.000000
```

### ğŸ“„ `Sistemas de Ecuaciones Lineales/MÃ©todos Iterativos.cpp`
**Jacobi, Gauss-Seidel y RelajaciÃ³n para sistemas grandes**

**ğŸ¯ QuÃ© hace:**
- **Jacobi:** IteraciÃ³n simultÃ¡nea con valores previos
- **Gauss-Seidel:** Usa valores actualizados inmediatamente  
- **RelajaciÃ³n:** Gauss-Seidel con factor de aceleraciÃ³n Ï‰

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar  
g++ -o iterativos "Sistemas de Ecuaciones Lineales/MÃ©todos Iterativos.cpp"

# Ejecutar (lee desde data.txt)
./iterativos
```

**ğŸ“Š MenÃº de selecciÃ³n:**
```
Seleccione:
1 --> Jacobi 
2 --> Gauss Seidel 
3 --> Gauss Seidel con RelajaciÃ³n
```

**âš¡ ParÃ¡metros de relajaciÃ³n:**
- `Ï‰ = 1`: Gauss-Seidel normal
- `Ï‰ < 1`: Sub-relajaciÃ³n (mejora convergencia en casos difÃ­ciles)
- `Ï‰ > 1`: Sobre-relajaciÃ³n (acelera convergencia)

## ğŸ“‰ RegresiÃ³n

### ğŸ“„ `Regresion/Regresion Lineal.cpp`
**RegresiÃ³n lineal por mÃ­nimos cuadrados con anÃ¡lisis estadÃ­stico**

**ğŸ¯ QuÃ© hace:**
- Ajusta recta y = aâ‚€ + aâ‚x a datos experimentales
- Calcula coeficientes por mÃ­nimos cuadrados
- AnÃ¡lisis estadÃ­stico: RÂ², error estÃ¡ndar, correlaciÃ³n

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o regresion-lineal "Regresion/Regresion Lineal.cpp"

# Ejecutar
./regresion-lineal
```

**ğŸ“Š Datos de ejemplo incluidos:**
```cpp
double m[ROWS][2];
m[0][0] = -1; m[0][1] = 10;
m[1][0] = 0;  m[1][1] = 9;
m[2][0] = 1;  m[2][1] = 7;
// ... mÃ¡s puntos
```

**ğŸ“ˆ Salida tÃ­pica:**
```
Matriz del sistema:
    28.000000    14.000000    38.000000
    14.000000     8.000000    38.000000

Conjunto soluciÃ³n:
X0 = -1.607143  (pendiente aâ‚)
X1 = 9.107143   (intercepto aâ‚€)

EcuaciÃ³n de regresiÃ³n: y = 9.107143 - 1.607143*x

El error cuadrÃ¡tico medio es de: 0.534522
El coeficiente de correlaciÃ³n es: 0.982745
```

### ğŸ“„ `Regresion/polynomialRegression.cpp`
**RegresiÃ³n polinÃ³mica de grado variable con anÃ¡lisis completo**

**ğŸ¯ QuÃ© hace:**
- Ajusta polinomio P(x) = aâ‚€ + aâ‚x + aâ‚‚xÂ² + ... + aâ‚™xâ¿
- Grado configurable segÃºn datos disponibles
- AnÃ¡lisis estadÃ­stico detallado
- ValidaciÃ³n automÃ¡tica de viabilidad

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o regresion-poli Regresion/polynomialRegression.cpp

# Ejecutar
./regresion-poli
```

**ğŸ“Š Datos incluidos:**
```cpp
double nodes[6][2] = {
    {0.2, -0.94}, {0.6, -0.26}, {1.3, 2.35},
    {1.4, 2.94},  {1.8, 5.45},  {2.0, 7.20}
};
```

**ğŸ“ SelecciÃ³n de grado:**
```
----------------------------
Ingresar grado del polinomio: 
----------------------------
2    â† Usuario ingresa grado deseado
```

## ğŸ“ˆ InterpolaciÃ³n

### ğŸ“„ `Interpolacion/interpolacion.cpp`
**MÃ©todos de Lagrange y Vandermonde con visualizaciÃ³n completa**

**ğŸ¯ QuÃ© hace:**
- **Lagrange:** Construye polinomio usando bases de Lagrange Li(x)
- **Vandermonde:** Resuelve sistema matricial para coeficientes
- ExpansiÃ³n automÃ¡tica a forma polinÃ³mica estÃ¡ndar P(x) = aâ‚€ + aâ‚x + ...

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o interpolacion Interpolacion/interpolacion.cpp

# Ejecutar (lee datos desde data.txt)
./interpolacion
```

**ğŸ“„ Formato archivo `data.txt`:**
```
0.309 3.02
0.300 2.93
0.292 2.85
0.285 2.78
0.270 2.63
```

**ğŸ“Š Salidas del programa:**

1. **Forma de Lagrange:**
```
P(x) = 3.02 * [(x-0.300)/(0.309-0.300) * (x-0.292)/(0.309-0.292) * ...]
     + 2.93 * [(x-0.309)/(0.300-0.309) * (x-0.292)/(0.300-0.292) * ...]
```

2. **Forma estÃ¡ndar expandida:**
```
P(x) = 2.1543*xÂ³ - 15.234*xÂ² + 45.678*x + 123.456
```

### ğŸ“„ `Interpolacion/Spline.cpp`
**Splines de grado variable - COMPLETAMENTE ADAPTABLE**

**ğŸ¯ QuÃ© hace:**
- Crea splines de **cualquier grado** (1=lineal, 2=cuadrÃ¡tico, 3=cÃºbico, etc.)
- Garantiza continuidad hasta derivada (grado-1)
- Condiciones de frontera naturales automÃ¡ticas
- VisualizaciÃ³n detallada por tramos

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o spline Interpolacion/Spline.cpp

# Ejecutar
./spline
```

**ğŸ“ Configurar grado del spline:**
```cpp
// En main(), lÃ­nea ~50:
int grado = 3;  // â† CAMBIAR AQUÃ EL GRADO DESEADO
// grado = 1: Spline lineal (Câ° - solo continuo)
// grado = 2: Spline cuadrÃ¡tico (CÂ¹ - continuo y derivable)  
// grado = 3: Spline cÃºbico (CÂ² - continuo hasta 2da derivada)
// grado = 4: Spline cuÃ¡rtico (CÂ³)
```

---

# ğŸ“‹ SEGUNDO PARCIAL

## ğŸ§® IntegraciÃ³n NumÃ©rica

### ğŸ“„ `Integracion/Integracion Newton Cotes.cpp`
**MÃ©todos de Trapecio y Simpson con menÃº interactivo completo**

**ğŸ¯ QuÃ© hace:**
- **Trapecio:** Aproxima Ã¡rea con trapecios (precisiÃ³n O(hÂ²))
- **Simpson:** Usa parÃ¡bolas para mayor precisiÃ³n (O(hâ´))
- Maneja funciones conocidas y datos tabulados
- DocumentaciÃ³n integrada completa

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o integracion "Integracion/Integracion Newton Cotes.cpp"

# Ejecutar
./integracion
```

**ğŸ“Š MenÃº interactivo:**
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        INTEGRACIÃ“N NUMÃ‰RICA (NEWTON-COTES)       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
0. Ver documentaciÃ³n de mÃ©todos
1. Trapecio - FunciÃ³n conocida      [f(x) = xÂ² + 1]
2. Trapecio - Tabla de datos        [puntos discretos]
3. Simpson Compuesto - FunciÃ³n      [f(x) = xÂ² + 1] 
4. Simpson Compuesto - Tabla        [puntos discretos]
5. Salir
```

**ğŸ“ FunciÃ³n actual:** `f(x) = xÂ² + 1`
```cpp
// Para cambiar funciÃ³n, modificar:
double funcion(double x){
    return pow(x,2) + 1;  // Tu funciÃ³n aquÃ­
}
```

### ğŸ“„ `Integracion/Gauss-Legendre.cpp`
**Cuadratura de Gauss-Legendre para alta precisiÃ³n**

**ğŸ¯ QuÃ© hace:**
- IntegraciÃ³n de alta precisiÃ³n con pocos puntos de evaluaciÃ³n
- Usa puntos y pesos pre-calculados Ã³ptimos
- Ã“rdenes disponibles: 2, 3, 4, 5, 6 puntos
- TransformaciÃ³n automÃ¡tica de intervalos

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o gauss-legendre Integracion/Gauss-Legendre.cpp

# Ejecutar
./gauss-legendre
```

**ğŸ“Š PrecisiÃ³n por orden:**

| Orden | Puntos | Exacto para polinomios hasta grado |
|-------|--------|-------------------------------------|
| 2 | 2 puntos | 3 |
| 3 | 3 puntos | 5 |
| 4 | 4 puntos | 7 |
| 5 | 5 puntos | 9 |
| 6 | 6 puntos | 11 |

## ğŸ“Š DerivaciÃ³n NumÃ©rica

### ğŸ“„ `Diferenciacion Numerica/Derivadas.cpp`
**Diferencias finitas para cÃ¡lculo de derivadas**

**ğŸ¯ QuÃ© hace:**
- **Progresivas:** `f'(x) â‰ˆ [f(x+h) - f(x)]/h` - Para inicio de intervalo
- **Regresivas:** `f'(x) â‰ˆ [f(x) - f(x-h)]/h` - Para final de intervalo  
- **Centrales:** `f'(x) â‰ˆ [f(x+h) - f(x-h)]/(2h)` - Mejor precisiÃ³n O(hÂ²)
- **Segunda derivada:** `f''(x) â‰ˆ [f(x+h) - 2f(x) + f(x-h)]/hÂ²`

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o derivadas "Diferenciacion Numerica/Derivadas.cpp"

# Ejecutar
./derivadas
```

**ğŸ“Š Datos tabulados incluidos:**
```cpp
double a[FILAS][2] = {
    {0,    1},     {0.25, 1.384}, {0.5,  1.849}, {0.75, 2.417},
    {1,    3.118}, {1.25, 3.99},  {1.5,  5.082}, {1.75, 6.45}, 
    {2,    8.189}
};
```

**âš¡ ComparaciÃ³n de mÃ©todos:**

| MÃ©todo | PrecisiÃ³n | UbicaciÃ³n | FÃ³rmula |
|--------|-----------|-----------|---------|
| **Progresiva** | O(h) | Extremo izquierdo | [f(x+h) - f(x)]/h |
| **Regresiva** | O(h) | Extremo derecho | [f(x) - f(x-h)]/h |
| **Central** | **O(hÂ²)** | **Punto interior** | **[f(x+h) - f(x-h)]/(2h)** â† Mejor |

### ğŸ“„ `Diferenciacion Numerica/Diferenciacion/Diferenciacion.cpp`
**ImplementaciÃ³n alternativa de diferenciaciÃ³n numÃ©rica**

**ğŸ¯ QuÃ© hace:**
- ImplementaciÃ³n bÃ¡sica de diferenciaciÃ³n
- FunciÃ³n recursiva para cÃ¡lculo de longitud de arrays
- VersiÃ³n simplificada para aprendizaje

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o diferenciacion "Diferenciacion Numerica/Diferenciacion/Diferenciacion.cpp"

# Ejecutar
./diferenciacion
```

## ğŸ”§ Ecuaciones Diferenciales

### ğŸ“„ `Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoEuler.cpp`
**MÃ©todo de Euler bÃ¡sico para EDO de primer orden**

**ğŸ¯ QuÃ© hace:**
- Resuelve EDO: `dy/dx = f(x,y)` con condiciÃ³n inicial `y(xâ‚€) = yâ‚€`
- MÃ©todo mÃ¡s simple: `yâ‚ = yâ‚€ + h*f(xâ‚€,yâ‚€)`
- PrecisiÃ³n O(h), fÃ¡cil de implementar

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o euler "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoEuler.cpp"

# Ejecutar
./euler
```

**ğŸ“ FunciÃ³n actual:** `f(x,y) = -2xy`
```cpp
// Para cambiar EDO, modificar:
double f(double x, double y){
    return (-2*x*y);  // Tu funciÃ³n f(x,y) aquÃ­
}
```

### ğŸ“„ `Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoHeun.cpp`
**MÃ©todo de Heun (Euler mejorado) - Predictor-Corrector**

**ğŸ¯ QuÃ© hace:**
- Esquema predictor-corrector para mayor precisiÃ³n
- **Predictor:** `y*â‚ = yâ‚€ + h*f(xâ‚€,yâ‚€)` (como Euler)
- **Corrector:** `yâ‚ = yâ‚€ + (h/2)[f(xâ‚€,yâ‚€) + f(xâ‚,y*â‚)]`
- PrecisiÃ³n O(hÂ²) - Mucho mejor que Euler

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar  
g++ -o heun "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoHeun.cpp"

# Ejecutar
./heun
```

### ğŸ“„ `Diferenciacion Numerica/Ecuaciones Diferenciales/Runge-Kutta4.cpp`
**Runge-Kutta 4to orden - El estÃ¡ndar de oro para EDO**

**ğŸ¯ QuÃ© hace:**
- MÃ©todo de 4to orden mÃ¡s utilizado en la prÃ¡ctica
- Calcula 4 coeficientes kâ‚, kâ‚‚, kâ‚ƒ, kâ‚„ por paso
- PrecisiÃ³n O(hâ´) - Excelente para la mayorÃ­a de problemas
- Muy estable y confiable

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o rk4 "Diferenciacion Numerica/Ecuaciones Diferenciales/Runge-Kutta4.cpp"

# Ejecutar
./rk4
```

**ğŸ“ FunciÃ³n actual:** `f(x,y) = xâˆšy`
```cpp
double f(double x, double y){
    return x*sqrt(y);  // Tu EDO aquÃ­: dy/dx = xâˆšy
}
```

**ğŸ”¬ Algoritmo interno:**
```
kâ‚ = f(xáµ¢, yáµ¢)
kâ‚‚ = f(xáµ¢ + h/2, yáµ¢ + kâ‚h/2)  
kâ‚ƒ = f(xáµ¢ + h/2, yáµ¢ + kâ‚‚h/2)
kâ‚„ = f(xáµ¢ + h, yáµ¢ + kâ‚ƒh)
yáµ¢â‚Šâ‚ = yáµ¢ + (h/6)(kâ‚ + 2kâ‚‚ + 2kâ‚ƒ + kâ‚„)
```

### ğŸ“„ `Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoPuntoMedio.cpp`
**MÃ©todo del Punto Medio con evaluaciÃ³n central**

**ğŸ¯ QuÃ© hace:**
- EvalÃºa la derivada en el punto medio del intervalo
- `yâ‚ = yâ‚€ + h*f(xâ‚€ + h/2, yâ‚€ + (h/2)*f(xâ‚€,yâ‚€))`
- PrecisiÃ³n O(hÂ²) con un enfoque diferente

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o punto-medio "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoPuntoMedio.cpp"

# Ejecutar  
./punto-medio
```

### ğŸ“„ `Diferenciacion Numerica/Ecuaciones Diferenciales/EjemploEcsDifDeOrdenSuperior.cpp`
**Sistemas de EDO usando Runge-Kutta - Orden superior reducido a primer orden**

**ğŸ¯ QuÃ© hace:**
- Resuelve EDO de orden superior convirtiÃ©ndolas en sistemas
- Ejemplo: `y'' + y = 4cos(x)` â†’ Sistema: `yâ‚' = yâ‚‚, yâ‚‚' = -yâ‚ + 4cos(x)`
- Aplica RK4 simultÃ¡neamente a ambas ecuaciones

**ğŸš€ CÃ³mo usar:**
```bash
# Compilar
g++ -o edo-superior "Diferenciacion Numerica/Ecuaciones Diferenciales/EjemploEcsDifDeOrdenSuperior.cpp"

# Ejecutar
./edo-superior
```

**ğŸ“Š Sistema actual:**
```cpp
double f1(double y2){
    return y2;  // yâ‚' = yâ‚‚
}
double f2(double x, double y1){  
    return -y1 + 4*cos(x);  // yâ‚‚' = -yâ‚ + 4cos(x)
}
```

---

# ğŸ’» GuÃ­a de Uso

## CompilaciÃ³n por Parciales

### ğŸ“‹ **PRIMER PARCIAL**
```bash
# LocalizaciÃ³n de RaÃ­ces
g++ -o biseccion LocRaices/Cerrados/Biseccion.cpp
g++ -o regula-falsi LocRaices/Cerrados/RegulaFalsi.cpp
g++ -o punto-fijo LocRaices/Abiertos/Punto-Fijo.cpp
g++ -o newton LocRaices/Abiertos/Newton-Raphson.cpp

# Sistemas de Ecuaciones
g++ -o gauss "Sistemas de Ecuaciones Lineales/Eliminacion-Gaussiana.cpp"
g++ -o iterativos "Sistemas de Ecuaciones Lineales/MÃ©todos Iterativos.cpp"

# RegresiÃ³n
g++ -o regresion-lineal "Regresion/Regresion Lineal.cpp"
g++ -o regresion-poli Regresion/polynomialRegression.cpp

# InterpolaciÃ³n
g++ -o interpolacion Interpolacion/interpolacion.cpp
g++ -o spline Interpolacion/Spline.cpp
```

### ğŸ“‹ **SEGUNDO PARCIAL**
```bash
# IntegraciÃ³n
g++ -o integracion "Integracion/Integracion Newton Cotes.cpp"
g++ -o gauss-legendre Integracion/Gauss-Legendre.cpp

# Derivadas
g++ -o derivadas "Diferenciacion Numerica/Derivadas.cpp"
g++ -o diferenciacion "Diferenciacion Numerica/Diferenciacion/Diferenciacion.cpp"

# Ecuaciones Diferenciales
g++ -o euler "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoEuler.cpp"
g++ -o heun "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoHeun.cpp"
g++ -o rk4 "Diferenciacion Numerica/Ecuaciones Diferenciales/Runge-Kutta4.cpp"
g++ -o punto-medio "Diferenciacion Numerica/Ecuaciones Diferenciales/MetodoPuntoMedio.cpp"
g++ -o edo-superior "Diferenciacion Numerica/Ecuaciones Diferenciales/EjemploEcsDifDeOrdenSuperior.cpp"
```

## ğŸ“– Ejemplos PrÃ¡cticos por Parcial

### ğŸ” **Ejemplo PRIMER PARCIAL: Sistema completo de anÃ¡lisis**

```bash
# 1. Encontrar raÃ­ces de f(x) = xÂ³ - 2x + 1
./newton        # Convergencia rÃ¡pida con derivada
./biseccion     # MÃ©todo robusto con intervalo

# 2. Resolver sistema 3x3
./gauss         # MÃ©todo directo
./iterativos    # MÃ©todo iterativo para sistemas grandes

# 3. Ajustar datos experimentales
./regresion-lineal    # RelaciÃ³n lineal
./regresion-poli      # RelaciÃ³n polinÃ³mica

# 4. Interpolar puntos
./interpolacion # Lagrange o Vandermonde
./spline       # Spline suave de grado variable
```

### ğŸ” **Ejemplo SEGUNDO PARCIAL: AnÃ¡lisis avanzado**

```bash
# 1. Calcular Ã¡rea bajo curva
./integracion   # MenÃº interactivo completo
./gauss-legendre # Alta precisiÃ³n

# 2. Calcular derivadas numÃ©ricas
./derivadas     # Diferencias finitas completas

# 3. Resolver EDO: dy/dt = -2y + x
./euler         # MÃ©todo bÃ¡sico
./heun          # Mejor precisiÃ³n
./rk4           # MÃ©todo estÃ¡ndar
./edo-superior  # Sistemas de EDO
```

## ğŸ“Š GuÃ­a de SelecciÃ³n por Parcial

### ğŸ“‹ **PRIMER PARCIAL - MÃ©todos Fundamentales**

| Problema | MÃ©todo Recomendado | CuÃ¡ndo usar |
|----------|-------------------|-------------|
| **RaÃ­z sin derivada** | BisecciÃ³n | MÃ¡xima robustez |
| **RaÃ­z con derivada** | Newton-Raphson | Convergencia sÃºper rÃ¡pida |
| **Sistema pequeÃ±o** | EliminaciÃ³n Gaussiana | SoluciÃ³n exacta |
| **Sistema grande** | MÃ©todos Iterativos | Eficiencia en memoria |
| **Datos lineales** | RegresiÃ³n Lineal | RelaciÃ³n simple |
| **Datos curvos** | RegresiÃ³n PolinÃ³mica | Mejor ajuste |
| **Pocos puntos** | Lagrange | InterpolaciÃ³n directa |
| **Muchos puntos** | Spline | Suavidad garantizada |

### ğŸ“‹ **SEGUNDO PARCIAL - AnÃ¡lisis Avanzado**

| Problema | MÃ©todo Recomendado | CuÃ¡ndo usar |
|----------|-------------------|-------------|
| **IntegraciÃ³n robusta** | Trapecio | Funciones irregulares |
| **IntegraciÃ³n precisa** | Simpson | Funciones suaves |
| **MÃ¡xima precisiÃ³n** | Gauss-Legendre | Pocos puntos disponibles |
| **Derivadas de tabla** | Diferencias Centrales | Mejor precisiÃ³n O(hÂ²) |
| **EDO simple** | Euler | Aprendizaje/comprensiÃ³n |
| **EDO precisiÃ³n media** | Heun | Balance costo/precisiÃ³n |
| **EDO aplicaciones** | Runge-Kutta 4 | EstÃ¡ndar industrial |
| **EDO orden superior** | Sistema RK4 | ConversiÃ³n a sistema |

## ğŸ› ï¸ ContribuciÃ³n

### CÃ³mo contribuir
1. **Fork** el repositorio
2. **Crear** rama: `git checkout -b feature/nueva-funcionalidad`
3. **Desarrollar** siguiendo las convenciones del proyecto
4. **Commit**: `git commit -m 'Add: nueva funcionalidad'`
5. **Push**: `git push origin feature/nueva-funcionalidad`
6. **Pull Request** con descripciÃ³n detallada

### Estilo de cÃ³digo
```cpp
// âœ… Nombres descriptivos en espaÃ±ol
void eliminacionGaussiana();
void interpolacionLagrange();

// âœ… Comentarios explicativos
// Aplica pivoteo parcial para evitar divisiÃ³n por cero

// âœ… Constantes definidas
#define FILAS 20
#define TOLERANCIA 1e-6

// âœ… ValidaciÃ³n de entrada
if (grado < 1 || grado > filas-1) {
    cout << "Error: grado invÃ¡lido" << endl;
    return;
}
```

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la **Licencia MIT**. Puedes usar, modificar y distribuir libremente.

## ğŸ‘¨â€ğŸ’» Autor

**CEGB03** - [GitHub](https://github.com/CEGB03)

---

## ğŸ“Š EstadÃ­sticas del Proyecto

### ğŸ“‹ **PRIMER PARCIAL**
| MÃ©trica | Valor |
|---------|-------|
| **MÃ©todos de raÃ­ces** | 4 |
| **MÃ©todos de sistemas** | 2 |
| **MÃ©todos de regresiÃ³n** | 2 |
| **MÃ©todos de interpolaciÃ³n** | 2 |
| **Total primer parcial** | **10 mÃ©todos** |

### ğŸ“‹ **SEGUNDO PARCIAL**
| MÃ©trica | Valor |
|---------|-------|
| **MÃ©todos de integraciÃ³n** | 2 |
| **MÃ©todos de derivaciÃ³n** | 2 |
| **MÃ©todos de EDO** | 5 |
| **Total segundo parcial** | **9 mÃ©todos** |

### ğŸ¯ **PROYECTO COMPLETO**
| MÃ©trica | Valor |
|---------|-------|
| **LÃ­neas de cÃ³digo** | ~4,500+ |
| **Archivos fuente** | 17+ |
| **MÃ©todos implementados** | **19 mÃ©todos** |
| **Ãreas cubiertas** | 7 |
| **Complejidad** | Intermedia-Avanzada |

---

**ğŸ“§ Â¿Preguntas o sugerencias?** 
Abre un [Issue](https://github.com/CEGB03/Metodos-Numericos-CPP/issues) o contribuye al proyecto.

**â­ Si este proyecto te ayudÃ³ en tus estudios, Â¡dale una estrella!**

**ğŸ”— Comparte** este repositorio con compaÃ±eros de ingenierÃ­a, matemÃ¡ticas o ciencias de la computaciÃ³n.

---

*Desarrollado con ğŸ’» y â˜• para la comunidad de mÃ©todos numÃ©ricos*

*Organizado por parciales para facilitar el estudio y la preparaciÃ³n de exÃ¡menes* ğŸ“šâœ¨